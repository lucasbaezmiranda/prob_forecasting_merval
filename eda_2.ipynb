{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d423b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = \"./market_data/\"\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
    "dfs = {fname.replace(\".csv\", \"\"): pd.read_csv(os.path.join(path, fname)) for fname in csv_files}\n",
    "\n",
    "def build_df_for_side(df, curr_side):\n",
    "    df_side = df[df[\"side\"] == curr_side]\n",
    "    if df_side.empty:\n",
    "        return pd.DataFrame(columns=[\"fecha_nano\", \"prices\", \"quantities\", \"side\"])\n",
    "    f = df_side[\"fecha_nano\"].to_numpy(dtype=np.int64)\n",
    "    p = df_side[\"price\"].to_numpy(dtype=np.float64)\n",
    "    q = df_side[\"quantity\"].to_numpy(dtype=np.float64)\n",
    "    order = np.argsort(f, kind=\"mergesort\")\n",
    "    f_s, p_s, q_s = f[order], p[order], q[order]\n",
    "    keys, idx, cnt = np.unique(f_s, return_index=True, return_counts=True)\n",
    "    starts, ends = idx, idx + cnt\n",
    "    rows = []\n",
    "    for s, e, k in zip(starts, ends, keys):\n",
    "        seg_p = p_s[s:e].astype(np.float64)\n",
    "        seg_q = q_s[s:e].astype(np.float64)\n",
    "        valid = np.isfinite(seg_p) & np.isfinite(seg_q) & (seg_q > 0) & (seg_p > 0)\n",
    "        seg_p = seg_p[valid]\n",
    "        seg_q = seg_q[valid]\n",
    "        rows.append({\"fecha_nano\": int(k), \"prices\": seg_p.tolist(), \"quantities\": seg_q.tolist(), \"side\": curr_side})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_metrics(df):\n",
    "    def _row_metrics(row):\n",
    "        prices = np.asarray(row[\"prices\"], dtype=float)\n",
    "        qtys = np.asarray(row[\"quantities\"], dtype=float)\n",
    "        valid = np.isfinite(prices) & np.isfinite(qtys) & (qtys > 0)\n",
    "        prices = prices[valid]\n",
    "        qtys = qtys[valid]\n",
    "        if qtys.size == 0 or np.nansum(qtys) == 0:\n",
    "            return pd.Series({\"vwap\": np.nan, \"spread\": np.nan})\n",
    "        vwap = np.average(prices, weights=qtys)\n",
    "        var = np.average((prices - vwap) ** 2, weights=qtys)\n",
    "        return pd.Series({\"vwap\": vwap, \"spread\": np.sqrt(var)})\n",
    "    metrics = df.apply(_row_metrics, axis=1)\n",
    "    return pd.concat([df[[\"fecha_nano\", \"side\"]].reset_index(drop=True), metrics], axis=1)\n",
    "\n",
    "all_series = {}\n",
    "all_frames = []\n",
    "\n",
    "for inst, df0 in dfs.items():\n",
    "    df0 = df0[[\"fecha_nano\", \"price\", \"quantity\", \"side\"]].dropna(subset=[\"price\", \"quantity\", \"side\"])\n",
    "    sides_present = df0[\"side\"].dropna().unique().tolist()\n",
    "    dfs_by_side = {s: build_df_for_side(df0, s) for s in sides_present}\n",
    "    if len(dfs_by_side) == 0:\n",
    "        continue\n",
    "    df_concat = pd.concat(dfs_by_side.values(), ignore_index=True)\n",
    "    df_metrics = build_metrics(df_concat).sort_values(\"fecha_nano\").reset_index(drop=True)\n",
    "    df_metrics[\"ts\"] = pd.to_datetime(df_metrics[\"fecha_nano\"], unit=\"ns\")\n",
    "    df_metrics[\"instrument\"] = inst\n",
    "\n",
    "    all_frames.append(df_metrics[[\"instrument\", \"side\", \"fecha_nano\", \"ts\", \"vwap\", \"spread\"]])\n",
    "\n",
    "    series_by_side = {\n",
    "        s: {\n",
    "            \"vwap\": df_metrics.loc[df_metrics[\"side\"] == s].set_index(\"fecha_nano\")[\"vwap\"],\n",
    "            \"spread\": df_metrics.loc[df_metrics[\"side\"] == s].set_index(\"fecha_nano\")[\"spread\"],\n",
    "        }\n",
    "        for s in df_metrics[\"side\"].unique()\n",
    "    }\n",
    "    all_series[inst] = series_by_side\n",
    "\n",
    "df_all = pd.concat(all_frames, ignore_index=True)\n",
    "\n",
    "required_sides = {\"BI\", \"OF\", \"TRADE\"}\n",
    "eligible = []\n",
    "for inst, d in all_series.items():\n",
    "    if not required_sides.issubset(set(d.keys())):\n",
    "        continue\n",
    "    ok = True\n",
    "    for s in required_sides:\n",
    "        ser = pd.Series(d[s]).dropna()\n",
    "        if ser.size == 0:\n",
    "            ok = False\n",
    "            break\n",
    "    if ok:\n",
    "        eligible.append(inst)\n",
    "\n",
    "selected_instruments = sorted(eligible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2097543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AL30_1205_CI_PESOS', 'PESOS-1305', 'AL30_1205_CI_CCL', 'AL30_1205_CI_MEP']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa48465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "target_instrument = \"AL30_1205_CI_CCL\"\n",
    "k_last = 3\n",
    "dt_median_window = 20\n",
    "\n",
    "df0 = df_all.copy()\n",
    "if \"ts\" not in df0.columns:\n",
    "    df0[\"ts\"] = pd.to_datetime(df0[\"fecha_nano\"], unit=\"ns\")\n",
    "\n",
    "trade = df0[df0[\"side\"]==\"TRADE\"][[\"instrument\",\"ts\",\"vwap\"]].dropna().sort_values([\"instrument\",\"ts\"])\n",
    "counts = trade.groupby(\"instrument\").size().sort_values(ascending=False)\n",
    "inst_pool = counts.index.tolist()\n",
    "if target_instrument not in inst_pool:\n",
    "    raise ValueError(\"Target instrument not found in df_all.\")\n",
    "others = [i for i in inst_pool if i!=target_instrument]\n",
    "selected = [target_instrument] + others[:4]\n",
    "\n",
    "def get_trade_df(inst):\n",
    "    d = trade[trade[\"instrument\"]==inst].sort_values(\"ts\").reset_index(drop=True)\n",
    "    d[\"t_sec\"] = d[\"ts\"].astype(\"int64\")/1e9\n",
    "    return d\n",
    "\n",
    "def fit_line_last3_at_t(d, t):\n",
    "    sub = d[d[\"ts\"]<=t].tail(k_last)\n",
    "    if len(sub)<k_last:\n",
    "        return np.nan, np.nan\n",
    "    x = sub[\"t_sec\"].to_numpy()\n",
    "    y = sub[\"vwap\"].astype(float).to_numpy()\n",
    "    xm = x.mean()\n",
    "    X = np.vstack([np.ones_like(x), (x-xm)]).T\n",
    "    a_c, b = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    t_sec = t.value/1e9\n",
    "    y_t = a_c + b*(t_sec - xm)\n",
    "    return float(y_t), float(b)\n",
    "\n",
    "dfs_trade = {inst: get_trade_df(inst) for inst in selected}\n",
    "\n",
    "t_grid = dfs_trade[target_instrument][\"ts\"].reset_index(drop=True)\n",
    "valid_rows = []\n",
    "for i in range(k_last-1, len(t_grid)-1):\n",
    "    t0 = t_grid.iloc[i]\n",
    "    t1 = t_grid.iloc[i+1]\n",
    "    row = {\"t0\": t0, \"t1\": t1}\n",
    "    ok = True\n",
    "    p_vec = {}\n",
    "    m_vec = {}\n",
    "    for inst in selected:\n",
    "        d = dfs_trade[inst]\n",
    "        if inst==target_instrument:\n",
    "            sub = d[d[\"ts\"]<=t0].tail(k_last)\n",
    "            if len(sub)<k_last:\n",
    "                ok=False; break\n",
    "            p_now_true = float(sub[\"vwap\"].iloc[-1])\n",
    "            _, m_now = fit_line_last3_at_t(d, t0)\n",
    "            p_vec[f\"p__{inst}\"] = p_now_true\n",
    "            m_vec[f\"m__{inst}\"] = m_now\n",
    "        else:\n",
    "            p_hat, m_hat = fit_line_last3_at_t(d, t0)\n",
    "            if np.isnan(p_hat) or np.isnan(m_hat):\n",
    "                ok=False; break\n",
    "            p_vec[f\"p__{inst}\"] = p_hat\n",
    "            m_vec[f\"m__{inst}\"] = m_hat\n",
    "    if not ok:\n",
    "        continue\n",
    "    d_tar = dfs_trade[target_instrument]\n",
    "    sub1 = d_tar[d_tar[\"ts\"]<=t1].tail(k_last)\n",
    "    if len(sub1)<k_last:\n",
    "        continue\n",
    "    _, m_next = fit_line_last3_at_t(d_tar, t1)\n",
    "    dt_next = (t1 - t0).total_seconds()\n",
    "    row.update(p_vec)\n",
    "    row.update(m_vec)\n",
    "    row[\"m_next\"] = m_next\n",
    "    row[\"dt_next\"] = dt_next\n",
    "    row[\"p_now\"] = p_vec[f\"p__{target_instrument}\"]\n",
    "    valid_rows.append(row)\n",
    "\n",
    "train = pd.DataFrame(valid_rows).dropna().reset_index(drop=True)\n",
    "\n",
    "feat_cols = [f\"p__{inst}\" for inst in selected] + [f\"m__{inst}\" for inst in selected]\n",
    "X = train[feat_cols].to_numpy(float)\n",
    "y = train[\"m_next\"].to_numpy(float)\n",
    "beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "x_last = train[feat_cols].iloc[-1].to_numpy(float)\n",
    "m_hat = float(x_last @ beta)\n",
    "\n",
    "d_tar = dfs_trade[target_instrument]\n",
    "dt_hist = d_tar[d_tar[\"ts\"]<=train[\"t0\"].iloc[-1]][\"ts\"].diff().dt.total_seconds().dropna()\n",
    "dt_hat = float(dt_hist.tail(dt_median_window).median()) if len(dt_hist)>0 else 1.0\n",
    "\n",
    "p0 = float(train[\"p_now\"].iloc[-1])\n",
    "p_next_hat = p0 + m_hat*dt_hat\n",
    "\n",
    "out_summary = {\n",
    "    \"selected_instruments\": selected,\n",
    "    \"n_samples\": int(len(train)),\n",
    "    \"last_t0\": str(train[\"t0\"].iloc[-1]),\n",
    "    \"p0\": p0,\n",
    "    \"m_hat\": m_hat,\n",
    "    \"dt_hat_sec\": dt_hat,\n",
    "    \"p_next_hat\": p_next_hat\n",
    "}\n",
    "out_summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
